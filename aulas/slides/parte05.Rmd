---
title: "Integração de Monte Carlo"
output: ioslides_presentation
---

## Introdução

- Integração de Monte Carlo é um método estatístico baseado em amostragem aleatória;
- Em 1777, Comte de Buffon utilizou experimentos aleatórios para determinar as probabilidades envolvidas no experimento da Agulha de Buffon;
- Gosset utilizou amostragem aleatória para estudar a distribuição $t$ de Student;

## Integração de Monte Carlo

- Seja $g(x)$ uma função;
- Deseja-se determinar $\int_a^b g(x)dx < \infty$;
- Note que se $X$ é uma v.a. com densidade $f(x)$, então: $$E[g(X)] = \int_{-\infty}^\infty g(x) f(x) dx.$$
- Então, se $X_1, \dots, X_n$ é uma amostra aleatória desta $f(x)$, então um estimador não-viciado de $E[g(X)]$ é a média amostral de $g(X_1), \dots, g(X_n)$.
$$\hat{\theta} = \overline{g(X)} = \frac{1}{n} \sum_{i=1}^n g(X_i)$$

## Estimador Simples de Monte Carlo

- Deseja-se estimar $\int_0^1 g(x) dx$;
- Se $X_1, \dots, X_n$ é uma a.a. de Uniforme(0,1), então
$$\hat{\theta} = \overline{g(X)} = \frac{1}{n} \sum_{i=1}^n g(X_i)$$
converge em probabilidade para $E[g(X)] = \theta$.
- Assim, o estimador simples de Monte Carlo para $\int_0^1 g(x) dx$ é $$\hat{\theta}=\overline{g(X)}$$.

## Exemplo

Determine uma estimativa de Monte Carlo para $\int_0^1 e^{-x} dx$.

## Exemplo

Determine uma estimativa de Monte Carlo para $\int_0^1 e^{-x} dx$.

```{r}
n = 1e5
unifs = runif(n)
gx = exp(-unifs)
mean(gx)
```

## Exemplo

Compare com o valor exato:
```{r}
mean(gx)
(gxExact = 1-exp(-1))
```

Compare também com uma aproximação:
```{r}
integrate(function(x) exp(-x), 0, 1)
```

## Qual é a magnitude do erro desta estimativa?

```{r}
estimaGx = function(n){
  unifs = runif(n)
  gx = exp(-unifs)
  return(mean(gx))
}
erroEstimativa = function(n){
  gxExact = 1-exp(-1)
  abs(gxExact-estimaGx(n))
}
```

## Magnitude do erro

```{r, fig.height=4, fig.width=4, fig.align='center'}
n = 10^(0:7)
erro = sapply(n, erroEstimativa)
plot(n, erro, xlab='Tamanho da Amostra', log='xy',
     ylab='Erro Absoluto', main=expression(e^{-x}))
```

## Mudando os Intervalos de Integração

- Para estimar $\int_a^b g(x)dx$, faça uma mudança de variáveis de modo que o novo intervalo seja $(0,1)$.
- Qual é essa transformação linear? 

## Mudando os Intervalos de Integração

- Para estimar $\int_a^b g(x)dx$, faça uma mudança de variáveis de modo que o novo intervalo seja $(0,1)$.
- Qual é essa transformação linear? 
$$y = \frac{x-a}{b-a}$$
$$dy = \frac{1}{b-a} dx$$

## Mudando os Intervalos de Integração
$$y = \frac{x-a}{b-a}$$
$$dy = \frac{1}{b-a} dx$$

$$
\int_a^b g(x)dx = \int_0^1 g(y(b-a)+b)(b-a)dy \\
$$
Alternativamente, utilize uma Uniforme(a,b):
$$\int_a^b g(x)dx = (b-a) \int_a^b g(x) \frac{1}{b-a}dx$$

## Exemplo

Determine uma estimativa de Monte Carlo para $\int_1^2 e^{-x} dx$.

```{r}
n = 1e5
unifs = runif(n, 1, 2)
gx = exp(-unifs)
mean(gx)
exp(-1) - exp(-2)
```

## Intervalos não-limitados

Determine uma estimativa de Monte Carlo para
$$\int_{-\infty}^x \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}} dt.$$

Note que o intervalo não-limitado impede o uso direto do algoritmo dado. Entretanto, use a simetria da distribuição normal e divida o problema em duas partes:

- $x \geq 0$
- $x < 0$

Assim o problema se resume a $\int_0^x \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}} dt$.

## Intervalos não-limitados

Assim o problema se resume a $\int_0^x e^{-\frac{t^2}{2}} dt$.

Efetuando a transformação de variáveis, temos:
$$
\begin{aligned}
y & = \frac{t}{x} \\
dt & = x dy \\
\theta & = \int_0^1 x e^{-\frac{(xy)^2}{2}} dy \\
\hat{\theta} & = E_Y\left[ x e^{-\frac{(xY)^2}{2}} \right]
\end{aligned}
$$

## Intervalos não-limitados

$$\hat{\theta} = E_Y\left[ x e^{-\frac{(xY)^2}{2}} \right]$$

```{r}
n = 1e6
unifs = runif(n)
xs = seq(0, 3, by=.5)
Fxs = function(x, unifs)
  1/2+mean(x*exp(-(x*unifs)^2/2))/sqrt(2*pi)
gx = sapply(xs, Fxs, unifs)
Phix = pnorm(xs)
out = rbind(gx, Phix)
colnames(out) = xs
round(out, 4)
```

## Se é Possível Simular $X$

Encontre um estimador de Monte Carlo para $F_X(x)$ para $X\sim N(0,1)$.

$$
F_X(x) = P(X \leq x) = E \left[ I(X \leq x) \right]
$$

Então, é suficiente gerar $X_1, \dots, X_n$ segundo uma Normal(0,1) e determinar a proporção de observações pertencentes ao evento $\{X \leq x\}$, para qualquer $x$ pré-especificado.

## Exemplo

$F_X(x)$ para $X\sim N(0,1)$:

```{r}
n = 1e6
xs = seq(0, 3, by=.5)
z = rnorm(n)
gx = sapply(xs, function(x, z) mean(z <= x), z)
Phix = pnorm(xs)
out = rbind(gx, Phix)
colnames(out) = xs
round(out, 4)
```


## O Erro-Padrão de $\hat{\theta} = \frac{1}{n} \sum g(x_i)$

$$
\mbox{V}(\hat{\theta}) = \frac{1}{n^2} \sum \mbox{V}_f\left[ g(x_i) \right] = \frac{\sigma^2}{n}
$$

Ao utilizarmos a distribuição empírica de $X$, temos:
$$ \mbox{V}_f\left[ g(X) \right] = \frac{1}{n} \sum_{i=1}^n \left[ g(x_i) - \overline{g(x)}\right]^2 $$

Assim:

$$
\begin{aligned}
\mbox{se}(\hat{\theta}) & = \frac{\sigma}{\sqrt{n}} = \frac{1}{n} \sqrt{\sum_{i=1}^n \left[ g(x_i) - \overline{g(x)}\right]^2}
\end{aligned}
$$

## IC para a Integral por Monte Carlo

Segundo o Teorema do Limite Central, temos: $$\frac{\hat{\theta_n} - E(\hat{\theta_n})}{\sqrt{V(\hat{\theta_n})}} \sim N(0, 1), \mbox{quando } n \rightarrow \infty$$

## Exemplo 1

Determine o IC(95%) para o estimador de Monte Carlo de $F_X(x)$, quando $X \sim Normal(0,1)$ e $x=1.75$, utilizando a esperança segundo uma distribuição Uniforme. Note que $F_X(1.75)=$ `r round(pnorm(1.75), 4)`.

```{r}
n = 1e6
x = 1.75
unifs = runif(n)
gx = 1/2+x*exp(-(x*unifs)^2/2)/sqrt(2*pi)
v = mean((gx-mean(gx))^2)/n
ic = round(mean(gx) + c(-1, 1) * 1.96*sqrt(v), 4)
ic
```

## Exemplo 2

Determine o IC(95%) para o estimador de Monte Carlo de $F_X(x)$, quando $X \sim Normal(0,1)$ e $x=1.75$, utilizando a esperança de uma função indicadora. Note que $F_X(1.75)=$ `r round(pnorm(1.75), 4)`.

```{r}
n = 1e6
x = 1.75
z = rnorm(n)
gx = z <= x
v = mean((gx-mean(gx))^2)/n
ic = round(mean(gx) + c(-1, 1) * 1.96*sqrt(v), 4)
ic
```

## Referências

Capítulo 5 - Maria Rizzo - Statistical Computing with R

